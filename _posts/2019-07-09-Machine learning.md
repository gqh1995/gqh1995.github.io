---
layout:     post
title:      Machine learning
subtitle:   机器学习算法个人总结
date:       2019-07-09
author:     gqhoshino
header-img: img/01.jpg
catalog: true
tags:
    - 机器学习
---
# Model：
可由训练改变的目标函数
通过降低loss函数的值（gradient decent）改变目标函数的参数（loss在线性问题中一般为均方差）
得到最好的目标函数

# 回归模型
### 线性回归：
- **f(x) = wxi+b ≈yi**
- w可为多个属性
### （判别式）逻辑回归：
- 线性模型套上激活函数可转为分类问题目标函数（s函数等）
- 多分类问题可引入softmax（对LR结果的归一化）-> 多个结果的概率 -> -标签结果和交叉熵的乘积
![完整的交叉熵公式。](/home/img/clipboard.png)

# 支持向量机（大间距分类器）
与逻辑回归类似--

# 聚类
## 性能度量：
- **簇内相似度高**
- **簇间相似度低**
- **聚类簇和参考簇对应考虑，根据对应信息有不同的度量标准**
## 距离度量（样本之间的聚类）
- **根据任务不同可以设计不同的距离度量**

## k均值
- **定聚类中心**
- **算距离分簇**
- **改变中心点的值（类内均值）**
- **再次算距离重新分配**
- **直到收敛**

## 高斯混合聚类（结合EM算法）
- 高斯混合聚类采用概率模型来表达聚类原型。换句话说，GMM聚类方法最终得到的是样本属于每个类别的概率，而不是像K均值那样将它直接归化为某一类别，因此也称为软聚类。
- 初始化：k个成分（k个高斯混合分布）
- E步：计算每个样本被每个成分生成的后验概率
- M步：反推各个混合成分的的参数，更新参数
- 根据样本由各个成分组成的后验概率来划分类别

## 层次聚类
- 树形结构
- 自底向上聚合
- 自顶向下拆分
