---
layout:     post
title:      推荐系统知识整理
subtitle:   知识整理
date:       2022-8-2
author:     gqhoshino
header-img: img/post-bg-kuaidi.jpg
catalog: true
tags:
    - 推荐系统
    - 协同过滤
    - 双塔模型
    - 精排、粗排
---
# 召回

## 协同过滤召回

### itemCF
原理：根据物品的相似性进行推荐
![](https://raw.githubusercontent.com/gqh1995/figurebed/main/img/20220812112121.png)
给用户推荐已选用过物品的相似物品，通过KG、或用户的行为。
如用户1选用物品1，用户2选用物品1的同时也选用了物品2。

打分：
基于训练数据中用户和物品的rating，计算物品之间的相似度，来推测用户对候选物品的兴趣得分大小。

#### user对item的兴趣得分
    ∑j like(user,itemj)sim(itemj,item)

物品间相似度计算方法：
基本概念为被相似的用户群体喜欢
物品i1和物品i2的相似度--
实际上是喜欢i1的用户向量与喜欢i2的用户向量的cos相似度。
* 变体swing，计算相似度时排除小圈子任务目标的影响，若V中的用户在小圈子内（有更多的重叠物品倾向），则相似度会偏低，α为超参数。

召回：
用户喜欢物品的TOP-k相似物品倒排作为召回结果进入pipeline的下一步。

### userCF
原理：根据用户的相似性进行推荐

打分：
基于训练数据中用户和物品的rating，计算用户之间的相似度，来推测用户对候选物品的兴趣得分大小。 

#### user对item的兴趣得分
    ∑j sim(user,userj)*like(userj,item)

用户间相似度计算方法：
基本概念为喜欢的物品集合相似
* 用户u1喜欢的物品记为J1
* 用户u2喜欢的物品记为J2
* 交集I = J1∩J2

#### tier1：两个用户的相似度
    sim(u1,u2) = |I|/√|J1|·|J2|

* nl为喜欢物品l的数量，反应物品的热门程度

#### tier2：降低热门物品权重
    sim(u1,u2) = ∑l∈I 1/log(1+nl)/√|J1|·|J2|

召回：
用户喜欢物品的TOP-k相似物品倒排作为召回结果进入pipeline的下一步。

## 向量召回

### 矩阵补充，最近邻查找
用户id和物品id向量化，训练用户id向量矩阵A和物品id向量矩阵B。
有监督训练，让真实rating接近物品和用户的向量相似度（内积）。最小化预测值和真实值的差。

为什么叫矩阵补充？
* 行作为用户，列作为物品，构成的矩阵为稀疏的，补充其实就是推荐的过程，给用户图鉴分数高的。

效果不好？ 
* 仅使用ID embedding，没利用物品用户的属性特征
* 负样本的选取方式不对，曝光后未选择的作为负样本，是错误做法
* 训练方法不好：内积不如cos， 平方损失（回归）不如交叉熵（分类）

最近邻查找算法？
* 要避免暴力枚举，因为物品可能很多
* 根据距离度量方法不同，划分向量空间，并记录索引
* 只用计算跟索引的相似度即可

### 双塔模型（DSSM）
把用户、物品属性考虑进模型的训练。
用户和物品的余弦相似度表示用户对物品的感兴趣分数

#### 物品的表征
* 将物品ID向量化
* 物品的离散特征向量化
* 物品的连续特征归一化，binning处理
* concatenate
* 进入神经网络得到表征

#### 用户的表征
* 将用户ID向量化
* 用户的离散特征向量化
* 用户的连续特征归一化，binning处理
* concatenate
* 进入神经网络得到表征

#### 训练
训练两个表征塔的神经网络。

训练方法：
* Pointwise：独立看待每个正负样本，做简单的二元分类
  
正负样本的数量大概为1:3
让cos(u,i+)大，cos(u,i-)小。

* Pairwise:每次取一个正样本、一个负样本
  
鼓励用户向量和正样本的相似度大于和负样本的相似度。

##### Triplet hinge loss:
    L(a,b+,b-) = max{0, cos(a,b-)+m-cos(a,b+)}

##### Triplet logsitc loss：
    L(a,b+,b-) = log(1+exp[Q·(cos(a,b-)-cos(a,b+))])

* Listwise：每次取一个正样本、多个负样本

鼓励a和b+的相似度尽量大，和b-尽量小。
损失函数为交叉熵，让正样本预测值与标签1接近，负样本和标签0接近。

正负样本的选择：
* 正样本：用户点击的物品
* 负样本：未被召回、召回后被排序淘汰、曝光未点击

# 排序
模型预测各种指标，得到得分。监督学习，用用户的真实行为训练预估模型。
## 多目标排序模型
用户特征，物品特征，统计特征，场景特征
|
contatenation
|
神经网络
|
点击率，点赞率，收藏值，转发率

分类任务，损失函数选用交叉熵。



# 冷启动策略